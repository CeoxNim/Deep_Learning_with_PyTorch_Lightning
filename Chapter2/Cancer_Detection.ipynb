{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchmetrics.functional import accuracy\n",
    "import pytorch_lightning as pl\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/histopathologic-cancer-detection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_labels = pd.read_csv(os.path.join(datapath, 'train_labels.csv'))\n",
    "cancer_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_labels['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. of images in train dataset: ', len(os.listdir(os.path.join(datapath, 'train'))))\n",
    "print('No. of images in test dataset:', len(os.listdir(os.path.join(datapath, 'test'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed to make the results replicable\n",
    "np.random.seed(0)\n",
    "train_imgs_orig = os.listdir(os.path.join(datapath, 'train'))\n",
    "selected_image_list = []\n",
    "for img in np.random.choice(train_imgs_orig, 10000):\n",
    "    selected_image_list.append(img)\n",
    "print(len(selected_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 6))\n",
    "for idx, img in enumerate(np.random.choice(selected_image_list, 20)):\n",
    "    ax = fig.add_subplot(2, 10, idx + 1, xticks=[], yticks=[])\n",
    "    im = Image.open(os.path.join(datapath, 'train', img))\n",
    "    plt.imshow(im)\n",
    "    lab = cancer_labels.loc[cancer_labels['id'] == img.split('.')[0], 'label'].values[0]\n",
    "    ax.set_title(f'Label: {lab}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.shuffle(selected_image_list)\n",
    "cancer_train_idx = selected_image_list[:8000]\n",
    "cancer_test_idx = selected_image_list[8000:]\n",
    "print(\"Number of images in the downsampled training dataset: \", len(cancer_train_idx))\n",
    "print(\"Number of images in the downsampled testing dataset: \", len(cancer_test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(datapath, 'train_dataset'))\n",
    "for fname in cancer_train_idx:\n",
    "    src = os.path.join(datapath, 'train', fname)\n",
    "    dst = os.path.join(datapath, 'train_dataset', fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "print('No. of images in downsampled training dataset: ', len(os.listdir(os.path.join(datapath, 'train_dataset'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(os.path.join(datapath, 'test_dataset'))\n",
    "for fname in cancer_test_idx:\n",
    "    src = os.path.join(datapath, 'train', fname)\n",
    "    dst = os.path.join(datapath, 'test_dataset', fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "print('No. of images in downsampled testing dataset: ', len(os.listdir(os.path.join(datapath, 'test_dataset'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T_train = T.Compose([\n",
    "    T.CenterCrop(32), \n",
    "    T.RandomHorizontalFlip(), \n",
    "    T.RandomVerticalFlip(), \n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T_test = T.Compose([\n",
    "    T.CenterCrop(32), \n",
    "    T.ToTensor(), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image_labels = pd.DataFrame()\n",
    "id_list = []\n",
    "label_list = []\n",
    "\n",
    "for img in selected_image_list:\n",
    "    label_tuple = cancer_labels.loc[cancer_labels['id'] == img.split('.')[0]]\n",
    "    id_list.append(label_tuple['id'].values[0])\n",
    "    label_list.append(label_tuple['label'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image_labels['id'] = id_list \n",
    "selected_image_labels['label'] = label_list \n",
    "selected_image_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with labels and ids of train data\n",
    "img_label_dict = {k: v for k, v in zip(selected_image_labels.id, selected_image_labels.label)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch lightning expects data to be in folders with the classes. We cannot use the DataLoader module directly when all train images are in one folder without subfolders. So, we will write out custom function to carry out the loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadCancerDataset(Dataset):\n",
    "    def __init__(self, data_folder, transform=T.Compose([T.CenterCrop(32), T.ToTensor()]), dict_labels={}):\n",
    "        self.data_folder = data_folder\n",
    "        self.list_image_files = [s for s in os.listdir(data_folder)]\n",
    "        self.transform = transform \n",
    "        self.dict_labels = dict_labels \n",
    "        self.labels = [dict_labels[i.split('.')[0]] for i in self.list_image_files]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.list_image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_folder, self.list_image_files[idx])\n",
    "        image = Image.open(img_name)\n",
    "        image = self.transform(image)\n",
    "        img_name_short = self.list_image_files[idx].split('.')[0]\n",
    "        label = self.dict_labels[img_name_short]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Load train data \n",
    "train_set = LoadCancerDataset(data_folder=os.path.join(datapath, 'train_dataset'), transform=data_T_train, dict_labels=img_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = LoadCancerDataset(data_folder=os.path.join(datapath, 'test_dataset'), transform=data_T_test, dict_labels=img_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 \n",
    "train_dataloader = DataLoader(train_set, batch_size, num_workers=4, pin_memory=True, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNImageClassifier(pl.LightningModule):\n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fully_connected_1 = nn.Linear(in_features=16 * 16 * 6,out_features=1000)\n",
    "        self.fully_connected_2 = nn.Linear(in_features=1000,out_features=500)\n",
    "        self.fully_connected_3 = nn.Linear(in_features=500,out_features=250)\n",
    "        self.fully_connected_4 = nn.Linear(in_features=250,out_features=120)\n",
    "        self.fully_connected_5 = nn.Linear(in_features=120,out_features=60)\n",
    "        self.fully_connected_6 = nn.Linear(in_features=60,out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = x.view(-1, 6*16*16)\n",
    "        x = self.fully_connected_1(x)\n",
    "        x = self.fully_connected_2(x)\n",
    "        x = self.fully_connected_3(x)\n",
    "        x = self.fully_connected_4(x)\n",
    "        x = self.fully_connected_5(x)\n",
    "        x = self.fully_connected_6(x)\n",
    "        return x \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch \n",
    "        outputs = self(inputs)\n",
    "        train_accuracy = accuracy(outputs, targets)\n",
    "        loss = self.loss(outputs, targets)\n",
    "        self.log('train_accuracy', train_accuracy, prog_bar=True)\n",
    "        self.log('train_loss', loss)\n",
    "        return {'loss': loss, 'train_accuracy': train_accuracy}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch \n",
    "        outputs = self(inputs)\n",
    "        test_accuracy = accuracy(outputs, targets)\n",
    "        loss = self.loss(outputs, targets)\n",
    "        self.log('test_accuracy', test_accuracy)\n",
    "        return {'test_loss': loss, 'test_accuracy': test_accuracy}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        params = self.parameters()\n",
    "        optimizer = optim.Adam(params=params, lr=self.learning_rate)\n",
    "        return optimizer \n",
    "    \n",
    "    # Calculate accuracy for each batch at a time \n",
    "    def binary_accuracy(self, outputs, targets):\n",
    "        _, outputs = torch.max(outputs, 1)\n",
    "        correct_results_sum = (outputs == targets).sum().float()\n",
    "        acc = correct_results_sum / targets.shape[0]\n",
    "        return acc \n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        return self(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNImageClassifier()\n",
    "trainer = pl.Trainer(fast_dev_run=True, accelerator='gpu', devices=1)\n",
    "trainer.fit(model, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = 'cnn_model_ckpts'\n",
    "ckpt_callback = pl.callbacks.ModelCheckpoint(every_n_epochs=10)\n",
    "\n",
    "model = CNNImageClassifier()\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=ckpt_dir, \n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    log_every_n_steps=25, \n",
    "    max_epochs=500,\n",
    "    callbacks=[ckpt_callback],\n",
    ")\n",
    "trainer.fit(model, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(test_dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.cuda()\n",
    "preds = []\n",
    "for batch_i, (data, target) in enumerate(test_dataloader):\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    output = model(data)\n",
    "    pr = output[:, 1].detach().cpu().numpy()\n",
    "    for i in pr:\n",
    "        preds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = pd.DataFrame({'imgs': test_set.list_image_files, 'labels':test_set.labels,  'preds': preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds['imgs'] = test_preds['imgs'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds['predictions'] = 1\n",
    "test_preds.loc[test_preds['preds'] < 0, 'predictions'] = 0\n",
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(test_preds['labels'] == test_preds['predictions'])[0])/test_preds.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c96765a009421011e24dd9d2f48d8665e98f4ec11c58c7b902d0fcdd52fc0ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
