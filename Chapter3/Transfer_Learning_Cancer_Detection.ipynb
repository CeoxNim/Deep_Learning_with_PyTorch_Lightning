{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import shutil \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import opendatasets as od \n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch \n",
    "from torch import nn, optim \n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision import transforms as T \n",
    "from torchvision.utils import make_grid \n",
    "from torchvision.models import resnet50 \n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "import pytorch_lightning as pl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the data downloaded in Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to the book Chapter 2 for downloading cancer dataset \n",
    "# I suppose you have downloaded the dataset and split it in Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f38a6374c348f90b587e046aac6079959adf3835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c18f2d887b7ae4f6742ee445113fa1aef383ed77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>755db6279dae599ebb4d39a9123cce439965282d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bc3f0c64fb968ff4a8bd33af6971ecae77c75e08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>068aba587a4950175d04c680d38943fd488d6a9d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  label\n",
       "0  f38a6374c348f90b587e046aac6079959adf3835      0\n",
       "1  c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
       "2  755db6279dae599ebb4d39a9123cce439965282d      0\n",
       "3  bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
       "4  068aba587a4950175d04c680d38943fd488d6a9d      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = '../data/histopathologic-cancer-detection'\n",
    "cancer_labels = pd.read_csv(os.path.join(datapath, 'train_labels.csv'))\n",
    "cancer_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9761\n"
     ]
    }
   ],
   "source": [
    "cancer_train_idx = os.listdir(os.path.join(datapath, 'train_dataset'))\n",
    "cancer_test_idx = os.listdir(os.path.join(datapath, 'test_dataset'))\n",
    "selected_image_list = cancer_train_idx + cancer_test_idx\n",
    "print(len(selected_image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the downsampled training dataset:  7772\n",
      "Number of images in the downsampled testing dataset:  1989\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in the downsampled training dataset: \", len(cancer_train_idx))\n",
    "print(\"Number of images in the downsampled testing dataset: \", len(cancer_test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image_labels = pd.DataFrame()\n",
    "\n",
    "id_list = []\n",
    "label_list = []\n",
    "for img in selected_image_list:\n",
    "    label_tuple = cancer_labels.loc[cancer_labels['id'] == img.split('.')[0]]\n",
    "    id_list.append(label_tuple['id'].values[0])\n",
    "    label_list.append(label_tuple['label'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_image_labels['id'] = id_list \n",
    "selected_image_labels['label'] = label_list \n",
    "selected_image_labels.head()\n",
    "\n",
    "img_class_dict = {k: v for k, v in zip(selected_image_labels.id, selected_image_labels.label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_T_train = T.Compose([\n",
    "    T.Resize(224), \n",
    "    T.RandomHorizontalFlip(), \n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "data_T_test = T.Compose([\n",
    "    T.Resize(224), \n",
    "    T.ToTensor(), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadCancerDataset(Dataset):\n",
    "    def __init__(self, datafolder, transform=T.Compose([T.CenterCrop(32), T.ToTensor()]), labels_dict={}):\n",
    "        self.datafolder = datafolder \n",
    "        self.image_files_list = [s for s in os.listdir(datafolder)]\n",
    "        self.transform = transform \n",
    "        self.labels_dict = labels_dict \n",
    "        self.labels = [labels_dict[i.split('.')[0]] for i in self.image_files_list]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.datafolder, self.image_files_list[idx])\n",
    "        image = Image.open(img_name)\n",
    "        image = self.transform(image)\n",
    "        img_name_short = self.image_files_list[idx].split('.')[0]\n",
    "        \n",
    "        label = self.labels_dict[img_name_short]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_train_set = LoadCancerDataset(\n",
    "    datafolder=os.path.join(datapath, 'train_dataset'), \n",
    "    transform=data_T_train, \n",
    "    labels_dict=img_class_dict, \n",
    ")\n",
    "\n",
    "cancer_test_set = LoadCancerDataset(\n",
    "    datafolder=os.path.join(datapath, 'test_dataset'),\n",
    "    transform=data_T_test, \n",
    "    labels_dict=img_class_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 \n",
    "cancer_train_loader = DataLoader(cancer_train_set, batch_size, num_workers=4, pin_memory=True, shuffle=True)\n",
    "cancer_test_loader = DataLoader(cancer_test_set, batch_size, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CeoxNim/anaconda3/envs/pl/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/CeoxNim/anaconda3/envs/pl/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerImageClassifier(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.pretrain_model = resnet50(pretrained=True)\n",
    "        self.pretrain_model.eval()\n",
    "\n",
    "        for param in self.pretrain_model.parameters():\n",
    "            param.requires_grad = False \n",
    "        \n",
    "        self.pretrain_model.fc = nn.Linear(2048, 2)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.pretrain_model(input)\n",
    "        return output \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch \n",
    "        outputs = self(inputs)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        train_accuracy = accuracy(preds, targets)\n",
    "        loss = self.loss(outputs, targets)\n",
    "\n",
    "        self.log('train_accuracy', train_accuracy, prog_bar=True)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        return {'loss': loss, 'train_accuracy': train_accuracy}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch \n",
    "        outputs = self(inputs)\n",
    "        \n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        test_accuracy = accuracy(preds, targets)\n",
    "        loss = self.loss(outputs, targets)\n",
    "        \n",
    "        self.log('test_accuracy', test_accuracy, prog_bar=True)\n",
    "        return {'test_loss': loss, 'test_accuracy': test_accuracy}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        test_outs = []\n",
    "        for test_out in outputs:\n",
    "            out = test_out['test_accuracy']\n",
    "            test_outs.append(out)\n",
    "        total_test_accuracy = torch.stack(test_outs).mean()\n",
    "        self.log('total_test_accuracy', total_test_accuracy, on_step=False, on_epoch=True)\n",
    "        return total_test_accuracy\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        params = self.parameters()\n",
    "        optimizer = optim.Adam(params=params, lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6]\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | loss           | CrossEntropyLoss | 0     \n",
      "1 | pretrain_model | ResNet           | 23.5 M\n",
      "----------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n",
      "/home/CeoxNim/anaconda3/envs/pl/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344740e111234b8da0d4cd72f1ebf3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    }
   ],
   "source": [
    "model = CancerImageClassifier()\n",
    "\n",
    "trainer = pl.Trainer(fast_dev_run=True, accelerator='gpu', devices=1)\n",
    "trainer.fit(model, cancer_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6]\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | loss           | CrossEntropyLoss | 0     \n",
      "1 | pretrain_model | ResNet           | 23.5 M\n",
      "----------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.049    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91c77ceae5d455eb70e99e22357fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = 'transfer_learning_Cancer_Detection_ckpts' \n",
    "ckpt_callback = pl.callbacks.ModelCheckpoint(every_n_epochs=10)\n",
    "\n",
    "model = CancerImageClassifier()\n",
    "trainer = pl.Trainer(default_root_dir=ckpt_dir, accelerator='gpu' , devices=1, callbacks=[ckpt_callback], log_every_n_steps=30, max_epochs=10)\n",
    "trainer.fit(model, cancer_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dda6dfa762f42b3af94b47739e8ea36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.8667672276496887\n",
      "   total_test_accuracy      0.8676828742027283\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_accuracy': 0.8667672276496887,\n",
       "  'total_test_accuracy': 0.8676828742027283}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, cancer_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# of course you can test model prediction and calculateing accuracy manually\n",
    "model.eval()\n",
    "preds = []\n",
    "for batch in cancer_test_loader:\n",
    "    inputs, targets = batch \n",
    "    targets = targets.cuda()\n",
    "    outputs = model(inputs)\n",
    "    preds.append(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgs</th>\n",
       "      <th>labels</th>\n",
       "      <th>preds</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bd2483c53a131c1461961f7c9a956815c2bc57cf.tif</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bd2483c53a131c1461961f7c9a956815c2bc57cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>348fb8796541e89e8b68a9c79d2448219408842e.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>348fb8796541e89e8b68a9c79d2448219408842e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>efd3aa82d00592883153920afb5fa059d935c867.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>efd3aa82d00592883153920afb5fa059d935c867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5f68ea08a11d32c6336797b51b860ae08ec0770a.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5f68ea08a11d32c6336797b51b860ae08ec0770a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a882824a42481564aff537df4cc09f33e915c528.tif</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a882824a42481564aff537df4cc09f33e915c528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           imgs  labels  preds  \\\n",
       "0  bd2483c53a131c1461961f7c9a956815c2bc57cf.tif       1      1   \n",
       "1  348fb8796541e89e8b68a9c79d2448219408842e.tif       0      0   \n",
       "2  efd3aa82d00592883153920afb5fa059d935c867.tif       0      1   \n",
       "3  5f68ea08a11d32c6336797b51b860ae08ec0770a.tif       0      0   \n",
       "4  a882824a42481564aff537df4cc09f33e915c528.tif       0      0   \n",
       "\n",
       "                                     images  \n",
       "0  bd2483c53a131c1461961f7c9a956815c2bc57cf  \n",
       "1  348fb8796541e89e8b68a9c79d2448219408842e  \n",
       "2  efd3aa82d00592883153920afb5fa059d935c867  \n",
       "3  5f68ea08a11d32c6336797b51b860ae08ec0770a  \n",
       "4  a882824a42481564aff537df4cc09f33e915c528  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = pd.DataFrame(\n",
    "    {\n",
    "        'imgs': cancer_test_set.image_files_list,\n",
    "        'labels': cancer_test_set.labels,\n",
    "        'preds': preds,\n",
    "    }\n",
    ")\n",
    "test_preds['images'] = test_preds['imgs'].apply(lambda x: x.split('.')[0])\n",
    "test_preds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c96765a009421011e24dd9d2f48d8665e98f4ec11c58c7b902d0fcdd52fc0ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
